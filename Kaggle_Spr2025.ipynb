{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "dee48435-8da5-4596-bd73-1fde1ee40578",
      "metadata": {
        "id": "dee48435-8da5-4596-bd73-1fde1ee40578"
      },
      "source": [
        "Natural Language Processing with Disaster Tweets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a notebook dedicated to the Natural Language Processing with Disaster Tweets Kaggle competition. In this competition, we will build a machine learning model that can predict whether a tweet is about a real disaster or not."
      ],
      "metadata": {
        "id": "EUAgAUDr08KK"
      },
      "id": "EUAgAUDr08KK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset: https://www.kaggle.com/competitions/nlp-getting-started/overview"
      ],
      "metadata": {
        "id": "f-n0_k_61BiG"
      },
      "id": "f-n0_k_61BiG"
    },
    {
      "cell_type": "markdown",
      "id": "b7f8706f-d0f6-4510-802b-3f1f7a9805dd",
      "metadata": {
        "id": "b7f8706f-d0f6-4510-802b-3f1f7a9805dd"
      },
      "source": [
        "Step 1: Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "381ce3c1-7f6f-41d5-a797-63b7e8351c2b",
      "metadata": {
        "id": "381ce3c1-7f6f-41d5-a797-63b7e8351c2b"
      },
      "outputs": [],
      "source": [
        "# Step 1: Import necessary libraries\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c4e6388-f10d-4091-bedc-320e089fc694",
      "metadata": {
        "id": "0c4e6388-f10d-4091-bedc-320e089fc694"
      },
      "source": [
        "Step 2: Load and Explore the Data\n",
        "Use pandas for loading and analyzing your datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e59d46e-a1c0-4b72-9570-699454c355b9",
      "metadata": {
        "id": "6e59d46e-a1c0-4b72-9570-699454c355b9"
      },
      "source": [
        "2.1. Data Collection and Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad5984ba-b0a5-415b-b447-6ac967b2fdf4",
      "metadata": {
        "id": "ad5984ba-b0a5-415b-b447-6ac967b2fdf4"
      },
      "source": [
        "Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d306ff6-e94b-4625-96d4-d5ceaeb5cc1a",
      "metadata": {
        "id": "4d306ff6-e94b-4625-96d4-d5ceaeb5cc1a"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(\"train.csv\")  # Training set\n",
        "test_df = pd.read_csv(\"test.csv\")  # Test set\n",
        "sample_submission_df = pd.read_csv(\"sample_submission.csv\")  # Sample submission format\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e702f224-8428-4c37-a050-97eff003cced",
      "metadata": {
        "id": "e702f224-8428-4c37-a050-97eff003cced",
        "outputId": "bfc03430-6c7f-4519-b59f-dfcd3798012b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   id keyword location                                               text  \\\n",
            "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
            "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
            "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
            "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
            "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
            "\n",
            "   target  \n",
            "0       1  \n",
            "1       1  \n",
            "2       1  \n",
            "3       1  \n",
            "4       1  \n",
            "   id keyword location                                               text\n",
            "0   0     NaN      NaN                 Just happened a terrible car crash\n",
            "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
            "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
            "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
            "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan\n",
            "   id  target\n",
            "0   0       0\n",
            "1   2       0\n",
            "2   3       0\n",
            "3   9       0\n",
            "4  11       0\n"
          ]
        }
      ],
      "source": [
        "# Quick overview of the data\n",
        "print(train_df.head())\n",
        "print(test_df.head())\n",
        "print(sample_submission_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c299992-cf92-4bd3-8084-4a80d6765277",
      "metadata": {
        "id": "0c299992-cf92-4bd3-8084-4a80d6765277"
      },
      "source": [
        "2.2. Display Data Structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33c691cb-36c4-41b0-bdf3-4d76484f87d2",
      "metadata": {
        "id": "33c691cb-36c4-41b0-bdf3-4d76484f87d2",
        "outputId": "6a9b2b72-81ed-4c22-f1d9-56dc060d8b07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Structure of The training datase :\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7613 entries, 0 to 7612\n",
            "Data columns (total 5 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   id        7613 non-null   int64 \n",
            " 1   keyword   7552 non-null   object\n",
            " 2   location  5080 non-null   object\n",
            " 3   text      7613 non-null   object\n",
            " 4   target    7613 non-null   int64 \n",
            "dtypes: int64(2), object(3)\n",
            "memory usage: 297.5+ KB\n",
            "None\n",
            "\n",
            "Structure ofThe test  dataset:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3263 entries, 0 to 3262\n",
            "Data columns (total 4 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   id        3263 non-null   int64 \n",
            " 1   keyword   3237 non-null   object\n",
            " 2   location  2158 non-null   object\n",
            " 3   text      3263 non-null   object\n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 102.1+ KB\n",
            "None\n",
            "\n",
            "Structure of A sample submission file dataset:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3263 entries, 0 to 3262\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype\n",
            "---  ------  --------------  -----\n",
            " 0   id      3263 non-null   int64\n",
            " 1   target  3263 non-null   int64\n",
            "dtypes: int64(2)\n",
            "memory usage: 51.1 KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nStructure of The training datase :\")\n",
        "print(train_df.info())\n",
        "\n",
        "print(\"\\nStructure ofThe test  dataset:\")\n",
        "print(test_df.info())\n",
        "\n",
        "print(\"\\nStructure of A sample submission file dataset:\")\n",
        "print(sample_submission_df.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63d6a8dd-de9d-4ecd-903d-60d4522826f7",
      "metadata": {
        "id": "63d6a8dd-de9d-4ecd-903d-60d4522826f7"
      },
      "source": [
        "3. Check for Missing Values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79f435bb-a1dc-4b81-93d5-b0d7ae63135f",
      "metadata": {
        "id": "79f435bb-a1dc-4b81-93d5-b0d7ae63135f",
        "outputId": "06fd1cde-abcf-461f-8d79-4c029f049abf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing values in training dataset:\n",
            " id             0\n",
            "keyword       61\n",
            "location    2533\n",
            "text           0\n",
            "target         0\n",
            "dtype: int64\n",
            "\n",
            "Missing values in testing dataset:\n",
            " id             0\n",
            "keyword       26\n",
            "location    1105\n",
            "text           0\n",
            "dtype: int64\n",
            "\n",
            "Missing values in samplesubmission dataset:\n",
            " id        0\n",
            "target    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"Missing values in training dataset:\\n\", train_df.isnull().sum())\n",
        "print(\"\\nMissing values in testing dataset:\\n\", test_df.isnull().sum())\n",
        "print(\"\\nMissing values in samplesubmission dataset:\\n\", sample_submission_df.isnull().sum())\n",
        "\n",
        "train_df = train_df.dropna()\n",
        "test_df = test_df.dropna()\n",
        "sample_submission_df = sample_submission_df.dropna()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cedbff6-a04b-427c-8b0f-ef4b05e1527a",
      "metadata": {
        "id": "5cedbff6-a04b-427c-8b0f-ef4b05e1527a",
        "outputId": "4526d0b6-1022-4166-a55a-ef3056d95002"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing values in training dataset:\n",
            " id          0\n",
            "keyword     0\n",
            "location    0\n",
            "text        0\n",
            "target      0\n",
            "dtype: int64\n",
            "\n",
            "Missing values in testing dataset:\n",
            " id          0\n",
            "keyword     0\n",
            "location    0\n",
            "text        0\n",
            "dtype: int64\n",
            "\n",
            "Missing values in samplesubmission dataset:\n",
            " id        0\n",
            "target    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"Missing values in training dataset:\\n\", train_df.isnull().sum())\n",
        "print(\"\\nMissing values in testing dataset:\\n\", test_df.isnull().sum())\n",
        "print(\"\\nMissing values in samplesubmission dataset:\\n\", sample_submission_df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc6c2231-97be-44c9-a37b-caaa1b4a6fd9",
      "metadata": {
        "id": "dc6c2231-97be-44c9-a37b-caaa1b4a6fd9"
      },
      "source": [
        "4. Drop Duplicates (Keep Only the First Occurrence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e0637b0-3d3e-456b-b443-8b3b81c6a445",
      "metadata": {
        "id": "1e0637b0-3d3e-456b-b443-8b3b81c6a445",
        "outputId": "cb1d41c1-5864-4ad9-cbab-255f9f026d21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "After dropping duplicates:\n",
            "Duplicates in trainning dataset: 0\n",
            "Duplicates in testing dataset: 0\n",
            "Duplicates in sample_submission dataset: 0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "train_df = train_df.drop_duplicates(keep='first')\n",
        "test_df = test_df.drop_duplicates(keep='first')\n",
        "sample_submission_df = sample_submission_df.drop_duplicates(keep='first')\n",
        "\n",
        "print(\"\\nAfter dropping duplicates:\")\n",
        "print(\"Duplicates in trainning dataset:\", train_df.duplicated().sum())\n",
        "print(\"Duplicates in testing dataset:\", test_df.duplicated().sum())\n",
        "print(\"Duplicates in sample_submission dataset:\", sample_submission_df.duplicated().sum())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61010ea4-7cbf-4d54-ba99-44e2cd42cb92",
      "metadata": {
        "id": "61010ea4-7cbf-4d54-ba99-44e2cd42cb92"
      },
      "source": [
        "5. Reset Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79547f7b-f79c-433c-a1df-ec3b55d48678",
      "metadata": {
        "id": "79547f7b-f79c-433c-a1df-ec3b55d48678"
      },
      "outputs": [],
      "source": [
        "train_df.reset_index(drop=True, inplace=True)\n",
        "test_df.reset_index(drop=True, inplace=True)\n",
        "sample_submission_df.reset_index(drop=True, inplace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b6f6ccb-ab1e-4d32-8e86-c9587efb70fa",
      "metadata": {
        "id": "8b6f6ccb-ab1e-4d32-8e86-c9587efb70fa"
      },
      "source": [
        "6. Display First and Last Records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30fd74e6-3a3e-4334-b3b5-b6927b9712b9",
      "metadata": {
        "id": "30fd74e6-3a3e-4334-b3b5-b6927b9712b9",
        "outputId": "9ed212e5-0b33-43fd-aa6f-c93553d429b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "First 5 records in training dataset:\n",
            "   id keyword                       location  \\\n",
            "0  48  ablaze                     Birmingham   \n",
            "1  49  ablaze  Est. September 2012 - Bristol   \n",
            "2  50  ablaze                         AFRICA   \n",
            "3  52  ablaze               Philadelphia, PA   \n",
            "4  53  ablaze                     London, UK   \n",
            "\n",
            "                                                text  target  \n",
            "0  @bbcmtd Wholesale Markets ablaze http://t.co/l...       1  \n",
            "1  We always try to bring the heavy. #metal #RT h...       0  \n",
            "2  #AFRICANBAZE: Breaking news:Nigeria flag set a...       1  \n",
            "3                 Crying out for more! Set me ablaze       0  \n",
            "4  On plus side LOOK AT THE SKY LAST NIGHT IT WAS...       0  \n",
            "\n",
            "Last 5 records in training dataset:\n",
            "         id  keyword                location  \\\n",
            "5075  10826  wrecked                      TN   \n",
            "5076  10829  wrecked  #NewcastleuponTyne #UK   \n",
            "5077  10831  wrecked       Vancouver, Canada   \n",
            "5078  10832  wrecked                 London    \n",
            "5079  10833  wrecked                 Lincoln   \n",
            "\n",
            "                                                   text  target  \n",
            "5075  On the bright side I wrecked http://t.co/uEa0t...       0  \n",
            "5076  @widda16 ... He's gone. You can relax. I thoug...       0  \n",
            "5077  Three days off from work and they've pretty mu...       0  \n",
            "5078  #FX #forex #trading Cramer: Iger's 3 words tha...       0  \n",
            "5079  @engineshed Great atmosphere at the British Li...       0  \n",
            "\n",
            "First 5 records in testing dataset:\n",
            "   id keyword                        location  \\\n",
            "0  46  ablaze                          London   \n",
            "1  47  ablaze  Niall's place | SAF 12 SQUAD |   \n",
            "2  51  ablaze                         NIGERIA   \n",
            "3  58  ablaze                  Live On Webcam   \n",
            "4  60  ablaze        Los Angeles, Califnordia   \n",
            "\n",
            "                                                text  \n",
            "0  Birmingham Wholesale Market is ablaze BBC News...  \n",
            "1  @sunkxssedharry will you wear shorts for race ...  \n",
            "2  #PreviouslyOnDoyinTv: Toke MakinwaÛªs marriag...  \n",
            "3  Check these out: http://t.co/rOI2NSmEJJ http:/...  \n",
            "4  PSA: IÛªm splitting my personalities.\\n\\n?? t...  \n",
            "\n",
            "Last 5 records in testing dataset:\n",
            "         id  keyword                          location  \\\n",
            "2153  10804  wrecked                        Love Reiss   \n",
            "2154  10806  wrecked                Seattle Washington   \n",
            "2155  10807  wrecked  Acey mountain islanddåÇTorontoåÈ   \n",
            "2156  10816  wrecked                       los angeles   \n",
            "2157  10820  wrecked                 Brussels, Belgium   \n",
            "\n",
            "                                                   text  \n",
            "2153  @yakubOObs think he deactivated because his no...  \n",
            "2154  RT CNBC '3 words from Disney CEO Bob Iger wrec...  \n",
            "2155  Smackdown tyme this should put me in a good mo...  \n",
            "2156  @thrillhho jsyk I haven't stopped thinking abt...  \n",
            "2157  @stighefootball Begovic has been garbage. He g...  \n",
            "\n",
            "First 5 records in sample_submission dataset:\n",
            "   id  target\n",
            "0   0       0\n",
            "1   2       0\n",
            "2   3       0\n",
            "3   9       0\n",
            "4  11       0\n",
            "\n",
            "Last 5 records in sample_submission dataset:\n",
            "         id  target\n",
            "3258  10861       0\n",
            "3259  10865       0\n",
            "3260  10868       0\n",
            "3261  10874       0\n",
            "3262  10875       0\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nFirst 5 records in training dataset:\")\n",
        "print(train_df.head())\n",
        "print(\"\\nLast 5 records in training dataset:\")\n",
        "print(train_df.tail())\n",
        "\n",
        "print(\"\\nFirst 5 records in testing dataset:\")\n",
        "print(test_df.head())\n",
        "print(\"\\nLast 5 records in testing dataset:\")\n",
        "print(test_df.tail())\n",
        "\n",
        "print(\"\\nFirst 5 records in sample_submission dataset:\")\n",
        "print(sample_submission_df.head())\n",
        "print(\"\\nLast 5 records in sample_submission dataset:\")\n",
        "print(sample_submission_df.tail())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66bdbf8c-90d8-4e21-8828-158c86a59af4",
      "metadata": {
        "id": "66bdbf8c-90d8-4e21-8828-158c86a59af4"
      },
      "source": [
        "7. Display Data  After"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b58a536e-61e6-41ef-8c41-dd79d7b796c9",
      "metadata": {
        "id": "b58a536e-61e6-41ef-8c41-dd79d7b796c9",
        "outputId": "049529a4-d1b7-4dde-d9b8-772c0d9aff53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Structure of The training datase :\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5080 entries, 0 to 5079\n",
            "Data columns (total 5 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   id        5080 non-null   int64 \n",
            " 1   keyword   5080 non-null   object\n",
            " 2   location  5080 non-null   object\n",
            " 3   text      5080 non-null   object\n",
            " 4   target    5080 non-null   int64 \n",
            "dtypes: int64(2), object(3)\n",
            "memory usage: 198.6+ KB\n",
            "None\n",
            "\n",
            "Structure ofThe test  dataset:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2158 entries, 0 to 2157\n",
            "Data columns (total 4 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   id        2158 non-null   int64 \n",
            " 1   keyword   2158 non-null   object\n",
            " 2   location  2158 non-null   object\n",
            " 3   text      2158 non-null   object\n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 67.6+ KB\n",
            "None\n",
            "\n",
            "Structure of A sample submission file dataset:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3263 entries, 0 to 3262\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype\n",
            "---  ------  --------------  -----\n",
            " 0   id      3263 non-null   int64\n",
            " 1   target  3263 non-null   int64\n",
            "dtypes: int64(2)\n",
            "memory usage: 51.1 KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nStructure of The training datase :\")\n",
        "print(train_df.info())\n",
        "\n",
        "print(\"\\nStructure ofThe test  dataset:\")\n",
        "print(test_df.info())\n",
        "\n",
        "print(\"\\nStructure of A sample submission file dataset:\")\n",
        "print(sample_submission_df.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eecbeb42-bd1a-4333-b74b-becf0d7b373b",
      "metadata": {
        "id": "eecbeb42-bd1a-4333-b74b-becf0d7b373b"
      },
      "source": [
        "8. Define a Function to Clean Text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f376582-b04e-40c5-8f30-ab3efd06c268",
      "metadata": {
        "id": "0f376582-b04e-40c5-8f30-ab3efd06c268"
      },
      "source": [
        "Defines stopwords (common words like \"the\", \"is\", \"and\") to be removed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2aae4f00-f20a-440a-b5d1-f445a0c3fca8",
      "metadata": {
        "id": "2aae4f00-f20a-440a-b5d1-f445a0c3fca8"
      },
      "outputs": [],
      "source": [
        "custom_stopwords = set([\n",
        "    \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\",\n",
        "    \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\",\n",
        "    \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\",\n",
        "    \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\",\n",
        "    \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\",\n",
        "    \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\",\n",
        "    \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\",\n",
        "    \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\",\n",
        "    \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\",\n",
        "    \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\",\n",
        "    \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\",\n",
        "    \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\",\n",
        "    \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\",\n",
        "    \"just\", \"don\", \"should\", \"now\"\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f50b11f0-5226-4760-b35d-61acf48cb20e",
      "metadata": {
        "id": "f50b11f0-5226-4760-b35d-61acf48cb20e"
      },
      "source": [
        " Step 5: Apply the Cleaning Function"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83e7a7c8-faa2-4e8d-9d0e-ce366e1f0c46",
      "metadata": {
        "id": "83e7a7c8-faa2-4e8d-9d0e-ce366e1f0c46"
      },
      "source": [
        "Cleans the text column (removes URLs, punctuation, stopwords).\n",
        "Stores the cleaned version in clean_text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7661d692-b4fc-4c7d-92a0-c66798b090c4",
      "metadata": {
        "id": "7661d692-b4fc-4c7d-92a0-c66798b090c4"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)  # Remove URLs\n",
        "    text = re.sub(r'<.*?>', '', text)  # Remove HTML tags\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)  # Remove special characters\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
        "    text = ' '.join([word for word in text.split() if word not in custom_stopwords])  # Remove stopwords manually\n",
        "    return text\n",
        "\n",
        "train_df['clean_text'] = train_df['text'].apply(clean_text)\n",
        "test_df['clean_text'] = test_df['text'].apply(clean_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "896b2238-349d-4b53-8667-a27f3ee54c2f",
      "metadata": {
        "id": "896b2238-349d-4b53-8667-a27f3ee54c2f"
      },
      "source": [
        "9. Convert Text to Numeric Features Using TF-IDF"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}