# Kaggle-Spr2025
Team - Alpharius


Jonathan Tran - Project Manager and Data Analyst


Kazuki Susuki - Client Liaison and Data Visualizer


Jeampy Kalambayi - Data Modeler and Project Documentation

### Description
This is a repo for the Natural Language Processing with Disaster Tweets (NLP with Disaster Tweets) Kaggle Competition. Due to the english language having certain words
be slang and not quite literal to the intended meaning of the actual word, some tweets may sound off. This project is an attempt to create a Natural Language Process code
that deciphers and identifies whether a tweets is announcing a literal disaster or if the tweet is being metaphorical. 

## Models Used
Below are the listed models used for Natural Language Processing. Please see model's notebook for results.

### Support Vector Machine
Support Vector Machine (SVMs) is a supervised learning model that is used for classification, regression, and outliers detection. 
This type of algorithm allows data to be serparated by margins and put into certain classifications. The results for SVMs are determined 
based on the data and parameters are used. In this case, kernel RBF is determined to be the best SVM result based on classification report. 
### BERT
BERT(Bidirectional Encoder Representations from Transformers) is a context-sensitive learning model used for classification tasks. It is an encoder-only
model that encodes input sequences into high dimensional embeddings.

Kaggle Link: https://www.kaggle.com/competitions/nlp-getting-started/data
